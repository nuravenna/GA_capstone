{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cynthiaowens/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/cynthiaowens/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = pd.read_csv('data/test_2.csv')\n",
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body', 'subreddit', 'word_count', 'clean_content', 'extreme'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great die hard trump supporter but i dont think those unhappy videos amount to much lots of good ugly green content',\n",
       " 'His family begged them to intervene but their big red dog ran past the small red house and ate some glad flowers full of yellow sunlight',\n",
       " 'my man sitting next to trumps right is so on point with his green sheep dreaming happy dreams of blue content and purple aliens',\n",
       " 'What a bitch the person writing this unpleasant post must be, they must be really unhappy and angry and unhappy and angry ',\n",
       " \"We'll have advance notice of them planning to attack because the children of their wealthy party members will leave our prestigious  and expensive colleges and flee to safety in huge numbers of cowardly and prestigious people with prestigious and advance information\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test2['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_adjectives(content):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    patterns = [\n",
    "        [{'POS':'ADJ'}],  # look for all adjective POS types\n",
    "    ]\n",
    "    matcher.add('placeholder', patterns)  # 'placeholder' is there bc add() requires 2 args, not sure what else to put there\n",
    "    \n",
    "    doc = nlp(content)\n",
    "    matches = matcher(doc)\n",
    "    adj_list = []\n",
    "    \n",
    "    # go thru the row and ID all adjectives-\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # string representation\n",
    "        span = doc[start:end]  # matched span\n",
    "        # append the adjectives to the adj_list to be counted, below-\n",
    "        adj_list.append(span.text)  \n",
    "        \n",
    "    # create an empty dictionary for our adjective count-\n",
    "    adj_count = {}\n",
    "\n",
    "    # add all IDed adjectives to the dictionary with a count of how many times they appear-\n",
    "    for adj in range(len(adj_list)):\n",
    "        adj_count[adj_list[adj]] = adj_list.count(\n",
    "            adj_list[adj]\n",
    "            )\n",
    "\n",
    "    return adj_count\n",
    "\n",
    "# from:\n",
    "# https://stackoverflow.com/questions/66790591/spacy-extraction-of-an-adjective-that-precede-a-verb-and-isnt-a-stop-word-nor\n",
    "# https://medium.com/swlh/create-a-dictionary-from-a-list-65742246ab4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {'great': 1, 'hard': 1, 'unhappy': 1, 'much': ...\n",
      "1    {'big': 1, 'red': 2, 'small': 1, 'glad': 1, 'f...\n",
      "2     {'green': 1, 'happy': 1, 'blue': 1, 'purple': 1}\n",
      "3          {'unpleasant': 1, 'unhappy': 2, 'angry': 2}\n",
      "4    {'advance': 1, 'wealthy': 1, 'prestigious': 3,...\n",
      "Name: body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test2['body'].map(count_adjectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'great': 1, 'hard': 1, 'unhappy': 1, 'much': 1, 'good': 1, 'ugly': 1, 'green': 1}, {'big': 1, 'red': 2, 'small': 1, 'glad': 1, 'full': 1, 'yellow': 1}, {'green': 1, 'happy': 1, 'blue': 1, 'purple': 1}, {'unpleasant': 1, 'unhappy': 2, 'angry': 2}, {'advance': 1, 'wealthy': 1, 'prestigious': 3, 'expensive': 1, 'huge': 1, 'cowardly': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(list(test2['body'].map(count_adjectives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function as above only returns a list of adjectives instead of a dictionary-\n",
    "\n",
    "def count_adjectives2(content):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    patterns = [\n",
    "        [{'POS':'ADJ'}],  # look for all adjective POS types\n",
    "    ]\n",
    "    matcher.add('placeholder', patterns)  # 'placeholder' is there bc add() requires 2 args, not sure what else to put there\n",
    "    \n",
    "    doc = nlp(content)\n",
    "    matches = matcher(doc)\n",
    "    adj_list = []\n",
    "    \n",
    "    # go thru the row and ID all adjectives-\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # string representation\n",
    "        span = doc[start:end]  # matched span\n",
    "        # append the adjectives to the adj_list to be counted, below-\n",
    "        adj_list.append(span.text)  \n",
    "        \n",
    "    # create an empty dictionary for our adjective count-\n",
    "#     adj_count = {}\n",
    "\n",
    "    # add all IDed adjectives to the dictionary with a count of how many times they appear-\n",
    "#     for adj in range(len(adj_list)):\n",
    "#         adj_count[adj_list[adj]] = adj_list.count(\n",
    "#             adj_list[adj]\n",
    "#             )\n",
    "\n",
    "    return adj_list\n",
    "\n",
    "# from:\n",
    "# https://stackoverflow.com/questions/66790591/spacy-extraction-of-an-adjective-that-precede-a-verb-and-isnt-a-stop-word-nor\n",
    "# https://medium.com/swlh/create-a-dictionary-from-a-list-65742246ab4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new column of list of adjectives for each post-\n",
    "\n",
    "test2['adjs'] = test2['body'].map(count_adjectives2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>extreme</th>\n",
       "      <th>adjs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great die hard trump supporter but i dont thin...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>die hard trump support dont think video amount...</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, hard, unhappy, much, good, ugly, green]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His family begged them to intervene but their ...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>6</td>\n",
       "      <td>famili beg interven</td>\n",
       "      <td>1</td>\n",
       "      <td>[big, red, small, red, glad, full, yellow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my man sitting next to trumps right is so on p...</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>11</td>\n",
       "      <td>man sit next trump right point</td>\n",
       "      <td>1</td>\n",
       "      <td>[green, happy, blue, purple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a bitch the person writing this unpleasan...</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>3</td>\n",
       "      <td>bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>[unpleasant, unhappy, angry, unhappy, angry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We'll have advance notice of them planning to ...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>28</td>\n",
       "      <td>we'll advanc notic plan attack children wealth...</td>\n",
       "      <td>1</td>\n",
       "      <td>[advance, wealthy, prestigious, expensive, hug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       subreddit  \\\n",
       "0  great die hard trump supporter but i dont thin...      The_Donald   \n",
       "1  His family begged them to intervene but their ...      The_Donald   \n",
       "2  my man sitting next to trumps right is so on p...  ChapoTrapHouse   \n",
       "3  What a bitch the person writing this unpleasan...  ChapoTrapHouse   \n",
       "4  We'll have advance notice of them planning to ...      The_Donald   \n",
       "\n",
       "   word_count                                      clean_content  extreme  \\\n",
       "0          13  die hard trump support dont think video amount...        1   \n",
       "1           6                                famili beg interven        1   \n",
       "2          11                     man sit next trump right point        1   \n",
       "3           3                                              bitch        1   \n",
       "4          28  we'll advanc notic plan attack children wealth...        1   \n",
       "\n",
       "                                                adjs  \n",
       "0    [great, hard, unhappy, much, good, ugly, green]  \n",
       "1         [big, red, small, red, glad, full, yellow]  \n",
       "2                       [green, happy, blue, purple]  \n",
       "3       [unpleasant, unhappy, angry, unhappy, angry]  \n",
       "4  [advance, wealthy, prestigious, expensive, hug...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so I've gotten this far. How can I now create a master dictionary that goes through each row dictionary, \n",
    "# returned above, and count the adjectives aggregating across (in this case) all 5 rows (but eventually to\n",
    "# run across much larger dfs)..? \n",
    "\n",
    "## flatten method?\n",
    "\n",
    "adjs_series = test2['body'].map(count_adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'great': 1, 'hard': 1, 'unhappy': 1, 'much': ...\n",
       "1    {'big': 1, 'red': 2, 'small': 1, 'glad': 1, 'f...\n",
       "2     {'green': 1, 'happy': 1, 'blue': 1, 'purple': 1}\n",
       "3          {'unpleasant': 1, 'unhappy': 2, 'angry': 2}\n",
       "4    {'advance': 1, 'wealthy': 1, 'prestigious': 3,...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjs_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adjs_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adj in adjs_series:\n",
    "    adj_dict.update(adj)\n",
    "    # check if key is there if not create otherwise sum it\n",
    "    \n",
    "    # concat ALL text together, then run above function across it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 1,\n",
       " 'hard': 1,\n",
       " 'unhappy': 2,\n",
       " 'much': 1,\n",
       " 'good': 1,\n",
       " 'ugly': 1,\n",
       " 'green': 1,\n",
       " 'big': 1,\n",
       " 'red': 2,\n",
       " 'small': 1,\n",
       " 'glad': 1,\n",
       " 'full': 1,\n",
       " 'yellow': 1,\n",
       " 'happy': 1,\n",
       " 'blue': 1,\n",
       " 'purple': 1,\n",
       " 'unpleasant': 1,\n",
       " 'angry': 2,\n",
       " 'advance': 1,\n",
       " 'wealthy': 1,\n",
       " 'prestigious': 3,\n",
       " 'expensive': 1,\n",
       " 'huge': 1,\n",
       " 'cowardly': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-count the vals (.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dict.update({'huge': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 1,\n",
       " 'hard': 1,\n",
       " 'unhappy': 2,\n",
       " 'much': 1,\n",
       " 'good': 1,\n",
       " 'ugly': 1,\n",
       " 'green': 1,\n",
       " 'big': 1,\n",
       " 'red': 2,\n",
       " 'small': 1,\n",
       " 'glad': 1,\n",
       " 'full': 1,\n",
       " 'yellow': 1,\n",
       " 'happy': 1,\n",
       " 'blue': 1,\n",
       " 'purple': 1,\n",
       " 'unpleasant': 1,\n",
       " 'angry': 2,\n",
       " 'advance': 1,\n",
       " 'wealthy': 1,\n",
       " 'prestigious': 3,\n",
       " 'expensive': 1,\n",
       " 'huge': 5,\n",
       " 'cowardly': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great die hard trump supporter but i dont think those unhappy videos amount to much lots of good ugly green content',\n",
       " 'His family begged them to intervene but their big red dog ran past the small red house and ate some glad flowers full of yellow sunlight',\n",
       " 'my man sitting next to trumps right is so on point with his green sheep dreaming happy dreams of blue content and purple aliens',\n",
       " 'What a bitch the person writing this unpleasant post must be, they must be really unhappy and angry and unhappy and angry ',\n",
       " \"We'll have advance notice of them planning to attack because the children of their wealthy party members will leave our prestigious  and expensive colleges and flee to safety in huge numbers of cowardly and prestigious people with prestigious and advance information\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test2['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = ', '.join(test2['body']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"great die hard trump supporter but i dont think those unhappy videos amount to much lots of good ugly green content, His family begged them to intervene but their big red dog ran past the small red house and ate some glad flowers full of yellow sunlight, my man sitting next to trumps right is so on point with his green sheep dreaming happy dreams of blue content and purple aliens, What a bitch the person writing this unpleasant post must be, they must be really unhappy and angry and unhappy and angry , We'll have advance notice of them planning to attack because the children of their wealthy party members will leave our prestigious  and expensive colleges and flee to safety in huge numbers of cowardly and prestigious people with prestigious and advance information\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 1,\n",
       " 'hard': 1,\n",
       " 'unhappy': 3,\n",
       " 'much': 1,\n",
       " 'good': 1,\n",
       " 'ugly': 1,\n",
       " 'green': 2,\n",
       " 'big': 1,\n",
       " 'red': 2,\n",
       " 'small': 1,\n",
       " 'glad': 1,\n",
       " 'full': 1,\n",
       " 'yellow': 1,\n",
       " 'happy': 1,\n",
       " 'blue': 1,\n",
       " 'purple': 1,\n",
       " 'unpleasant': 1,\n",
       " 'angry': 2,\n",
       " 'advance': 1,\n",
       " 'wealthy': 1,\n",
       " 'prestigious': 3,\n",
       " 'expensive': 1,\n",
       " 'huge': 1,\n",
       " 'cowardly': 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_adjectives(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/subreddits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body               0\n",
       "subreddit          0\n",
       "word_count         0\n",
       "tokenized        275\n",
       "clean_content    275\n",
       "extreme            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body             0\n",
       "subreddit        0\n",
       "word_count       0\n",
       "tokenized        0\n",
       "clean_content    0\n",
       "extreme          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extrem = data.loc[data['extreme'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19812, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_extrem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body', 'subreddit', 'word_count', 'tokenized', 'clean_content',\n",
       "       'extreme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_extrem.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = data_extrem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_full = ', '.join(sub['tokenized']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full = count_adjectives(test_list_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_sort(dict_to_sort):\n",
    "    adj_list = []\n",
    "    \n",
    "    for key, value in sorted(dict_to_sort.items(), key=lambda x: x[1], reverse = True):\n",
    "        if value >=10:\n",
    "            adj_list.append([key, value])\n",
    "\n",
    "    return adj_list\n",
    "\n",
    "# from Sean McNamara, Q5 answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['good', 443],\n",
       " ['bad', 234],\n",
       " ['fucking', 216],\n",
       " ['many', 215],\n",
       " ['right', 192],\n",
       " ['white', 178],\n",
       " ['much', 166],\n",
       " ['great', 146],\n",
       " ['big', 137],\n",
       " ['real', 132],\n",
       " ['political', 130],\n",
       " ['little', 126],\n",
       " ['first', 123],\n",
       " ['american', 121],\n",
       " ['old', 121],\n",
       " ['new', 118],\n",
       " ['sure', 116],\n",
       " ['better', 112],\n",
       " ['true', 109],\n",
       " ['last', 108],\n",
       " ['wrong', 105],\n",
       " ['best', 101],\n",
       " ['black', 101],\n",
       " ['free', 94],\n",
       " ['fake', 94],\n",
       " ['whole', 87],\n",
       " ['full', 84],\n",
       " ['liberal', 83],\n",
       " ['long', 83],\n",
       " ['leftist', 79],\n",
       " ['high', 79],\n",
       " ['least', 76],\n",
       " ['social', 75],\n",
       " ['funny', 74],\n",
       " ['different', 70],\n",
       " ['enough', 65],\n",
       " ['actual', 65],\n",
       " ['public', 65],\n",
       " ['next', 64],\n",
       " ['red', 63],\n",
       " ['top', 62],\n",
       " ['stupid', 62],\n",
       " ['non', 61],\n",
       " ['nice', 60],\n",
       " ['military', 59],\n",
       " ['anti', 59],\n",
       " ['possible', 57],\n",
       " ['rich', 56],\n",
       " ['single', 56],\n",
       " ['racist', 56],\n",
       " ['conservative', 55],\n",
       " ['entire', 54],\n",
       " ['human', 53],\n",
       " ['crazy', 52],\n",
       " ['poor', 51],\n",
       " ['open', 50],\n",
       " ['dumb', 50],\n",
       " ['important', 50],\n",
       " ['chinese', 49],\n",
       " ['western', 48],\n",
       " ['current', 47],\n",
       " ['sad', 47],\n",
       " ['huge', 47],\n",
       " ['deep', 47],\n",
       " ['evil', 47],\n",
       " ['due', 46],\n",
       " ['worse', 45],\n",
       " ['less', 45],\n",
       " ['hard', 44],\n",
       " ['mental', 43],\n",
       " ['second', 43],\n",
       " ['small', 42],\n",
       " ['corrupt', 42],\n",
       " ['dead', 42],\n",
       " ['socialist', 41],\n",
       " ['legal', 41],\n",
       " ['sorry', 41],\n",
       " ['foreign', 40],\n",
       " ['general', 40],\n",
       " ['low', 40],\n",
       " ['cool', 39],\n",
       " ['pro', 39],\n",
       " ['female', 39],\n",
       " ['young', 39],\n",
       " ['gay', 39],\n",
       " ['personal', 38],\n",
       " ['weird', 38],\n",
       " ['normal', 38],\n",
       " ['worth', 38],\n",
       " ['happy', 38],\n",
       " ['certain', 37],\n",
       " ['bunch', 37],\n",
       " ['fair', 37],\n",
       " ['local', 37],\n",
       " ['interesting', 36],\n",
       " ['middle', 35],\n",
       " ['late', 35],\n",
       " ['live', 35],\n",
       " ['serious', 35],\n",
       " ['national', 35],\n",
       " ['holy', 35],\n",
       " ['hot', 34],\n",
       " ['shitty', 34],\n",
       " ['massive', 34],\n",
       " ['russian', 34],\n",
       " ['fine', 33],\n",
       " ['honest', 33],\n",
       " ['front', 33],\n",
       " ['average', 33],\n",
       " ['special', 32],\n",
       " ['blue', 32],\n",
       " ['sick', 32],\n",
       " ['future', 32],\n",
       " ['third', 32],\n",
       " ['awesome', 31],\n",
       " ['higher', 31],\n",
       " ['obvious', 31],\n",
       " ['modern', 31],\n",
       " ['illegal', 31],\n",
       " ['able', 30],\n",
       " ['several', 30],\n",
       " ['republican', 30],\n",
       " ['private', 30],\n",
       " ['strong', 30],\n",
       " ['correct', 30],\n",
       " ['major', 30],\n",
       " ['damn', 29],\n",
       " ['smart', 29],\n",
       " ['net', 29],\n",
       " ['biggest', 29],\n",
       " ['clear', 29],\n",
       " ['amazing', 28],\n",
       " ['male', 28],\n",
       " ['common', 28],\n",
       " ['secret', 28],\n",
       " ['worst', 27],\n",
       " ['hilarious', 27],\n",
       " ['ready', 27],\n",
       " ['criminal', 27],\n",
       " ['perfect', 26],\n",
       " ['ethnic', 26],\n",
       " ['total', 26],\n",
       " ['large', 26],\n",
       " ['beautiful', 25],\n",
       " ['absolute', 25],\n",
       " ['federal', 25],\n",
       " ['medical', 25],\n",
       " ['violent', 25],\n",
       " ['left', 25],\n",
       " ['close', 25],\n",
       " ['communist', 25],\n",
       " ['mad', 24],\n",
       " ['fun', 24],\n",
       " ['insane', 24],\n",
       " ['negative', 24],\n",
       " ['easy', 23],\n",
       " ['early', 23],\n",
       " ['false', 23],\n",
       " ['half', 23],\n",
       " ['exact', 23],\n",
       " ['angry', 23],\n",
       " ['global', 23],\n",
       " ['multiple', 22],\n",
       " ['powerful', 22],\n",
       " ['sexual', 22],\n",
       " ['complete', 22],\n",
       " ['popular', 22],\n",
       " ['original', 21],\n",
       " ['corporate', 21],\n",
       " ['ridiculous', 21],\n",
       " ['green', 21],\n",
       " ['lower', 21],\n",
       " ['glad', 21],\n",
       " ['capitalist', 21],\n",
       " ['kind', 21],\n",
       " ['democratic', 20],\n",
       " ['pathetic', 20],\n",
       " ['libertarian', 20],\n",
       " ['terrible', 20],\n",
       " ['cultural', 20],\n",
       " ['official', 19],\n",
       " ['positive', 19],\n",
       " ['giant', 19],\n",
       " ['simple', 19],\n",
       " ['straight', 19],\n",
       " ['civil', 19],\n",
       " ['safe', 19],\n",
       " ['guilty', 19],\n",
       " ['bigger', 19],\n",
       " ['dark', 19],\n",
       " ['economic', 19],\n",
       " ['basic', 19],\n",
       " ['proud', 19],\n",
       " ['fat', 19],\n",
       " ['progressive', 19],\n",
       " ['tired', 18],\n",
       " ['homeless', 18],\n",
       " ['cold', 18],\n",
       " ['brave', 18],\n",
       " ['former', 18],\n",
       " ['super', 18],\n",
       " ['mean', 18],\n",
       " ['impossible', 18],\n",
       " ['marxist', 18],\n",
       " ['reasonable', 18],\n",
       " ['past', 18],\n",
       " ['recent', 18],\n",
       " ['mass', 17],\n",
       " ['various', 17],\n",
       " ['useful', 17],\n",
       " ['daily', 17],\n",
       " ['ill', 17],\n",
       " ['critical', 17],\n",
       " ['german', 17],\n",
       " ['primary', 17],\n",
       " ['similar', 17],\n",
       " ['short', 17],\n",
       " ['nuclear', 17],\n",
       " ['imperialist', 17],\n",
       " ['weak', 17],\n",
       " ['financial', 17],\n",
       " ['opposite', 17],\n",
       " ['surprised', 17],\n",
       " ['religious', 17],\n",
       " ['favorite', 17],\n",
       " ['easier', 17],\n",
       " ['native', 17],\n",
       " ['useless', 16],\n",
       " ['upper', 16],\n",
       " ['direct', 16],\n",
       " ['disgusting', 16],\n",
       " ['independent', 16],\n",
       " ['authoritarian', 16],\n",
       " ['main', 16],\n",
       " ['ignorant', 16],\n",
       " ['extra', 16],\n",
       " ['equal', 16],\n",
       " ['canadian', 16],\n",
       " ['british', 16],\n",
       " ['online', 16],\n",
       " ['willing', 15],\n",
       " ['subject', 15],\n",
       " ['dirty', 15],\n",
       " ['greatest', 15],\n",
       " ['brown', 15],\n",
       " ['retarded', 15],\n",
       " ['imperial', 15],\n",
       " ['moral', 15],\n",
       " ['radical', 15],\n",
       " ['specific', 15],\n",
       " ['natural', 14],\n",
       " ['bullshit', 14],\n",
       " ['previous', 14],\n",
       " ['older', 14],\n",
       " ['electoral', 14],\n",
       " ['okay', 14],\n",
       " ['endless', 14],\n",
       " ['younger', 14],\n",
       " ['alive', 14],\n",
       " ['constitutional', 14],\n",
       " ['muslim', 14],\n",
       " ['difficult', 14],\n",
       " ['available', 14],\n",
       " ['sweet', 14],\n",
       " ['particular', 14],\n",
       " ['fascist', 14],\n",
       " ['decent', 14],\n",
       " ['necessary', 14],\n",
       " ['awful', 14],\n",
       " ['light', 14],\n",
       " ['wealthy', 13],\n",
       " ['excellent', 13],\n",
       " ['reactionary', 13],\n",
       " ['quid', 13],\n",
       " ['lazy', 13],\n",
       " ['presidential', 13],\n",
       " ['slow', 13],\n",
       " ['typical', 13],\n",
       " ['highest', 13],\n",
       " ['south', 13],\n",
       " ['https', 13],\n",
       " ['physical', 12],\n",
       " ['dangerous', 12],\n",
       " ['quick', 12],\n",
       " ['significant', 12],\n",
       " ['brutal', 12],\n",
       " ['stable', 12],\n",
       " ['turkish', 12],\n",
       " ['ukrainian', 12],\n",
       " ['aware', 12],\n",
       " ['terrorist', 12],\n",
       " ['expensive', 12],\n",
       " ['double', 12],\n",
       " ['accountable', 12],\n",
       " ['jewish', 12],\n",
       " ['potential', 12],\n",
       " ['european', 12],\n",
       " ['individual', 12],\n",
       " ['larger', 12],\n",
       " ['proper', 12],\n",
       " ['pure', 12],\n",
       " ['famous', 12],\n",
       " ['innocent', 12],\n",
       " ['sexist', 12],\n",
       " ['likely', 12],\n",
       " ['final', 11],\n",
       " ['regular', 11],\n",
       " ['busy', 11],\n",
       " ['successful', 11],\n",
       " ['legitimate', 11],\n",
       " ['horrible', 11],\n",
       " ['complex', 11],\n",
       " ['vast', 11],\n",
       " ['ironic', 11],\n",
       " ['wonderful', 11],\n",
       " ['revolutionary', 11],\n",
       " ['earlier', 11],\n",
       " ['accurate', 11],\n",
       " ['constant', 11],\n",
       " ['international', 11],\n",
       " ['christian', 11],\n",
       " ['empty', 11],\n",
       " ['acceptable', 11],\n",
       " ['literal', 11],\n",
       " ['dem', 11],\n",
       " ['realistic', 11],\n",
       " ['fellow', 11],\n",
       " ['racial', 11],\n",
       " ['heavy', 10],\n",
       " ['traditional', 10],\n",
       " ['degenerate', 10],\n",
       " ['responsible', 10],\n",
       " ['standard', 10],\n",
       " ['ongoing', 10],\n",
       " ['fuckin', 10],\n",
       " ['curious', 10],\n",
       " ['ugly', 10],\n",
       " ['smaller', 10],\n",
       " ['capable', 10],\n",
       " ['genuine', 10],\n",
       " ['idiot', 10],\n",
       " ['desperate', 10],\n",
       " ['ok', 10],\n",
       " ['interested', 10],\n",
       " ['active', 10],\n",
       " ['grand', 10],\n",
       " ['random', 10],\n",
       " ['drunk', 10],\n",
       " ['toxic', 10],\n",
       " ['strange', 10],\n",
       " ['feminist', 10],\n",
       " ['afraid', 10],\n",
       " ['crooked', 10],\n",
       " ['domestic', 10],\n",
       " ['legit', 10],\n",
       " ['usual', 10],\n",
       " ['scary', 10],\n",
       " ['cheap', 10],\n",
       " ['incredible', 10],\n",
       " ['lucky', 10],\n",
       " ['extreme', 10],\n",
       " ['temporary', 10],\n",
       " ['greta', 10]]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adj_sort(test_full)\n",
    "\n",
    "# DO NOT RERUN!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list_GS = pd.read_csv('data/adjectives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[['good', 443],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['bad', 234],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['fucking', 216],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['many', 215],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['right', 192],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>['incredible', 10],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>['lucky', 10],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>['extreme', 10],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>['temporary', 10],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>['greta', 10]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              adjectives\n",
       "0        [['good', 443],\n",
       "1          ['bad', 234],\n",
       "2      ['fucking', 216],\n",
       "3         ['many', 215],\n",
       "4        ['right', 192],\n",
       "..                   ...\n",
       "358  ['incredible', 10],\n",
       "359       ['lucky', 10],\n",
       "360     ['extreme', 10],\n",
       "361   ['temporary', 10],\n",
       "362       ['greta', 10]]\n",
       "\n",
       "[363 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_list_GS['adjectives'] = adj_list_GS['adjectives'].str.replace('[', '')\n",
    "# adj_list_GS['adjectives'] = adj_list_GS['adjectives'].str.replace(']', '')\n",
    "# adj_list_GS['adjectives'] = adj_list_GS['adjectives'].str.replace(\"'\", '')\n",
    "adj_list_GS['adjectives'] = adj_list_GS['adjectives'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good 443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad 234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fucking 216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many 215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right 192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>incredible 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>lucky 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>extreme 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>temporary 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>greta 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        adjectives\n",
       "0         good 443\n",
       "1          bad 234\n",
       "2      fucking 216\n",
       "3         many 215\n",
       "4        right 192\n",
       "..             ...\n",
       "358  incredible 10\n",
       "359       lucky 10\n",
       "360     extreme 10\n",
       "361   temporary 10\n",
       "362       greta 10\n",
       "\n",
       "[363 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list_GS = adj_list_GS['adjectives'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list_GS = adj_list_GS.rename(columns={'0': 'adjective', '1': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fucking</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>incredible</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>lucky</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>extreme</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>temporary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>greta</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1\n",
       "0          good  443\n",
       "1           bad  234\n",
       "2       fucking  216\n",
       "3          many  215\n",
       "4         right  192\n",
       "..          ...  ...\n",
       "358  incredible   10\n",
       "359       lucky   10\n",
       "360     extreme   10\n",
       "361   temporary   10\n",
       "362       greta   10\n",
       "\n",
       "[363 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list = pd.read_csv('data/adjectives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[['good', 443],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['bad', 234],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['fucking', 216],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['many', 215],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['right', 192],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>['incredible', 10],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>['lucky', 10],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>['extreme', 10],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>['temporary', 10],</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>['greta', 10]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              adjectives\n",
       "0        [['good', 443],\n",
       "1          ['bad', 234],\n",
       "2      ['fucking', 216],\n",
       "3         ['many', 215],\n",
       "4        ['right', 192],\n",
       "..                   ...\n",
       "358  ['incredible', 10],\n",
       "359       ['lucky', 10],\n",
       "360     ['extreme', 10],\n",
       "361   ['temporary', 10],\n",
       "362       ['greta', 10]]\n",
       "\n",
       "[363 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_list['adjectives'] = adj_list['adjectives'].str.replace('[', '')\n",
    "# adj_list['adjectives'] = adj_list['adjectives'].str.replace(']', '')\n",
    "# adj_list['adjectives'] = adj_list['adjectives'].str.replace(\"'\", '')\n",
    "adj_list['adjectives'] = adj_list['adjectives'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good 443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad 234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fucking 216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many 215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right 192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>incredible 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>lucky 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>extreme 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>temporary 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>greta 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        adjectives\n",
       "0         good 443\n",
       "1          bad 234\n",
       "2      fucking 216\n",
       "3         many 215\n",
       "4        right 192\n",
       "..             ...\n",
       "358  incredible 10\n",
       "359       lucky 10\n",
       "360     extreme 10\n",
       "361   temporary 10\n",
       "362       greta 10\n",
       "\n",
       "[363 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list = adj_list['adjectives'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fucking</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>right</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>incredible</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>lucky</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>extreme</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>temporary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>greta</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1\n",
       "0          good  443\n",
       "1           bad  234\n",
       "2       fucking  216\n",
       "3          many  215\n",
       "4         right  192\n",
       "..          ...  ...\n",
       "358  incredible   10\n",
       "359       lucky   10\n",
       "360     extreme   10\n",
       "361   temporary   10\n",
       "362       greta   10\n",
       "\n",
       "[363 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list.rename(columns={0: 'adjective', 1: 'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list['count']=adj_list['count'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363 entries, 0 to 362\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   adjective  363 non-null    object \n",
      " 1   count      363 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "adj_list.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tuple_to_dect(tup, dic):\n",
    "#     for a, b in tup:\n",
    "#         dic.setdefault(a, []).append(b)\n",
    "#     return dic\n",
    "\n",
    "# https://www.geeksforgeeks.org/python-convert-list-tuples-dictionary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_dict = {}\n",
    "# tuple_to_dect(sorted_dict, adj_dict)\n",
    "\n",
    "# https://www.geeksforgeeks.org/python-convert-list-tuples-dictionary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use matcher function and apply to pull out adjectives from 3-row df, then pull out from 100 rows, then full df\n",
    "\n",
    "# do the same thing for named entities, subjects (nsubj dependencies)\n",
    "# also can limit the models to run over just the adjectives, entities, subjects\n",
    "# (instead of running across entire count vectorozed or tfidf-ed words in corpus)\n",
    "# logreg, svm, bayes, tree models, CNN, huggingface transfer models\n",
    "# 40_000 observations in input set for models: equal classes, 20_000 extremist subs, 20_000 non-extremist subs\n",
    "# (either politics or another, less similar subreddit although you need time to scrape it!-- might have to\n",
    "# use a smaller input set in that case)\n",
    "# maybe use TIL/FFT reddit posts? check average word counts, make sure to remove TILs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that takes in a sentence, IDs and counts the adjectives-\n",
    "\n",
    "def count_adjectives(sent):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    patterns = [\n",
    "        [{'POS':'ADJ'}],\n",
    "    ]\n",
    "    matcher.add('placeholder', patterns)  # 'placeholder' is there bc add() requires 2 args, not sure what else to put there\n",
    "    \n",
    "    doc = nlp(sent)\n",
    "    matches = matcher(doc)\n",
    "    adj_list = []\n",
    "    \n",
    "    # go thru the sentence and ID all adjectives-\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # string representation\n",
    "        span = doc[start:end]  # matched span\n",
    "        # append the adjectives to the adj_list to be counted, below-\n",
    "        adj_list.append(span.text)  \n",
    "        \n",
    "    # create an empty dictionary for our adjective count-\n",
    "    adj_count = {}\n",
    "\n",
    "    # add all IDed adjectives to the dictionary with a count of how many times they appear-\n",
    "    for pos in range(len(adj_list)):\n",
    "        adj_count[adj_list[pos]] = adj_list.count(\n",
    "            adj_list[pos]\n",
    "            )\n",
    "\n",
    "    return adj_count\n",
    "\n",
    "# from:\n",
    "# https://stackoverflow.com/questions/66790591/spacy-extraction-of-an-adjective-that-precede-a-verb-and-isnt-a-stop-word-nor\n",
    "# https://medium.com/swlh/create-a-dictionary-from-a-list-65742246ab4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'the big red dog ran past the small red house'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'big': 1, 'red': 2, 'small': 1}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_adjectives(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>extreme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die hard trump supporter but i dont think thos...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>die hard trump support dont think video amount...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His family begged them to intervene.</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>6</td>\n",
       "      <td>famili beg interven</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my man sitting next to trumps right is so on p...</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>11</td>\n",
       "      <td>man sit next trump right point</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a bitch</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>3</td>\n",
       "      <td>bitch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We'll have advance notice of them planning to ...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>28</td>\n",
       "      <td>we'll advanc notic plan attack children wealth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       subreddit  \\\n",
       "0  die hard trump supporter but i dont think thos...      The_Donald   \n",
       "1               His family begged them to intervene.      The_Donald   \n",
       "2  my man sitting next to trumps right is so on p...  ChapoTrapHouse   \n",
       "3                                       What a bitch  ChapoTrapHouse   \n",
       "4  We'll have advance notice of them planning to ...      The_Donald   \n",
       "\n",
       "   word_count                                      clean_content  extreme  \n",
       "0          13  die hard trump support dont think video amount...        1  \n",
       "1           6                                famili beg interven        1  \n",
       "2          11                     man sit next trump right point        1  \n",
       "3           3                                              bitch        1  \n",
       "4          28  we'll advanc notic plan attack children wealth...        1  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = extrem.head()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>extreme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great die hard trump supporter but i dont thin...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>die hard trump support dont think video amount...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His family begged them to intervene but their ...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>6</td>\n",
       "      <td>famili beg interven</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my man sitting next to trumps right is so on p...</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>11</td>\n",
       "      <td>man sit next trump right point</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a bitch the person writing this unpleasan...</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>3</td>\n",
       "      <td>bitch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We'll have advance notice of them planning to ...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>28</td>\n",
       "      <td>we'll advanc notic plan attack children wealth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       subreddit  \\\n",
       "0  great die hard trump supporter but i dont thin...      The_Donald   \n",
       "1  His family begged them to intervene but their ...      The_Donald   \n",
       "2  my man sitting next to trumps right is so on p...  ChapoTrapHouse   \n",
       "3  What a bitch the person writing this unpleasan...  ChapoTrapHouse   \n",
       "4  We'll have advance notice of them planning to ...      The_Donald   \n",
       "\n",
       "   word_count                                      clean_content  extreme  \n",
       "0          13  die hard trump support dont think video amount...        1  \n",
       "1           6                                famili beg interven        1  \n",
       "2          11                     man sit next trump right point        1  \n",
       "3           3                                              bitch        1  \n",
       "4          28  we'll advanc notic plan attack children wealth...        1  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = pd.read_csv('data/test_2.csv')\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the function so that it can be run across a df (body column), creating a new column listing each adjective in that row-\n",
    "\n",
    "def count_adjectives_df(content):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    patterns = [\n",
    "        [{'POS':'ADJ'}],\n",
    "    ]\n",
    "    matcher.add('placeholder', patterns)  # 'placeholder' is there bc add() requires 2 args, not sure what else to put there\n",
    "    \n",
    "    doc = nlp(content)\n",
    "    matches = matcher(doc)\n",
    "    adj_list = []\n",
    "    \n",
    "    # go thru the sentence and ID all adjectives-\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # string representation\n",
    "        span = doc[start:end]  # matched span\n",
    "        # append the adjectives to the adj_list-\n",
    "        adj_list.append(span.text)  \n",
    "    \n",
    "    return ' '.join(adj_list)\n",
    "\n",
    "\n",
    "# from:\n",
    "# https://stackoverflow.com/questions/66790591/spacy-extraction-of-an-adjective-that-precede-a-verb-and-isnt-a-stop-word-nor\n",
    "# https://medium.com/swlh/create-a-dictionary-from-a-list-65742246ab4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2['adjectives'] = test2['body'].map(count_adjectives_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>extreme</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great die hard trump supporter but i dont thin...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>13</td>\n",
       "      <td>die hard trump support dont think video amount...</td>\n",
       "      <td>1</td>\n",
       "      <td>great hard unhappy much good ugly green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>His family begged them to intervene but their ...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>6</td>\n",
       "      <td>famili beg interven</td>\n",
       "      <td>1</td>\n",
       "      <td>big red small red glad full yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my man sitting next to trumps right is so on p...</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>11</td>\n",
       "      <td>man sit next trump right point</td>\n",
       "      <td>1</td>\n",
       "      <td>green happy blue purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What a bitch the person writing this unpleasan...</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>3</td>\n",
       "      <td>bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>unpleasant unhappy angry unhappy angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We'll have advance notice of them planning to ...</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>28</td>\n",
       "      <td>we'll advanc notic plan attack children wealth...</td>\n",
       "      <td>1</td>\n",
       "      <td>advance wealthy prestigious expensive huge cow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body       subreddit  \\\n",
       "0  great die hard trump supporter but i dont thin...      The_Donald   \n",
       "1  His family begged them to intervene but their ...      The_Donald   \n",
       "2  my man sitting next to trumps right is so on p...  ChapoTrapHouse   \n",
       "3  What a bitch the person writing this unpleasan...  ChapoTrapHouse   \n",
       "4  We'll have advance notice of them planning to ...      The_Donald   \n",
       "\n",
       "   word_count                                      clean_content  extreme  \\\n",
       "0          13  die hard trump support dont think video amount...        1   \n",
       "1           6                                famili beg interven        1   \n",
       "2          11                     man sit next trump right point        1   \n",
       "3           3                                              bitch        1   \n",
       "4          28  we'll advanc notic plan attack children wealth...        1   \n",
       "\n",
       "                                          adjectives  \n",
       "0            great hard unhappy much good ugly green  \n",
       "1                 big red small red glad full yellow  \n",
       "2                            green happy blue purple  \n",
       "3             unpleasant unhappy angry unhappy angry  \n",
       "4  advance wealthy prestigious expensive huge cow...  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that takes in a sentence, IDs and counts the adjectives-\n",
    "\n",
    "def count_adjectives(sent):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    patterns = [\n",
    "        [{'POS':'ADJ'}],\n",
    "    ]\n",
    "    matcher.add('placeholder', patterns)  # 'placeholder' is there bc add() requires 2 args, not sure what else to put there\n",
    "    \n",
    "    doc = nlp(sent)\n",
    "    matches = matcher(doc)\n",
    "    adj_list = []\n",
    "    \n",
    "    # go thru the sentence and ID all adjectives-\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # string representation\n",
    "        span = doc[start:end]  # matched span\n",
    "        # append the adjectives to the adj_list to be counted, below-\n",
    "        adj_list.append(span.text)  \n",
    "        \n",
    "    # create an empty dictionary for our adjective count-\n",
    "    adj_count = {}\n",
    "\n",
    "    # add all IDed adjectives to the dictionary with a count of how many times they appear-\n",
    "    for adj in range(len(adj_list)):\n",
    "        adj_count[adj_list[adj]] = adj_list.count(\n",
    "            adj_list[adj]\n",
    "            )\n",
    "\n",
    "    return adj_count\n",
    "\n",
    "# from:\n",
    "# https://stackoverflow.com/questions/66790591/spacy-extraction-of-an-adjective-that-precede-a-verb-and-isnt-a-stop-word-nor\n",
    "# https://medium.com/swlh/create-a-dictionary-from-a-list-65742246ab4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {'great': 1, 'hard': 1, 'unhappy': 1, 'much': ...\n",
      "1    {'big': 1, 'red': 2, 'small': 1, 'glad': 1, 'f...\n",
      "2     {'green': 1, 'happy': 1, 'blue': 1, 'purple': 1}\n",
      "3          {'unpleasant': 1, 'unhappy': 2, 'angry': 2}\n",
      "4    {'advance': 1, 'wealthy': 1, 'prestigious': 3,...\n",
      "Name: body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test2['body'].map(count_adjectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_adj_count = []\n",
    "master_adj_count.append(test2['body'].map(count_adjectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0    {'great': 1, 'hard': 1, 'unhappy': 1, 'much': ...\n",
       " 1    {'big': 1, 'red': 2, 'small': 1, 'glad': 1, 'f...\n",
       " 2     {'green': 1, 'happy': 1, 'blue': 1, 'purple': 1}\n",
       " 3          {'unpleasant': 1, 'unhappy': 2, 'angry': 2}\n",
       " 4    {'advance': 1, 'wealthy': 1, 'prestigious': 3,...\n",
       " Name: body, dtype: object]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_adj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using the cvec lemmatizer\n",
    "# try concatenating the word_count column to the best-performing text column\n",
    "# try using spacy processing in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
